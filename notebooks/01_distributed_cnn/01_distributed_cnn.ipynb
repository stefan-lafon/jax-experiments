{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNz4nBMVLptIZPLsPqE3Akg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"RrHgyoCkyL_c","executionInfo":{"status":"ok","timestamp":1768785297065,"user_tz":480,"elapsed":16,"user":{"displayName":"Stefan Lafon","userId":"17149650627927548318"}},"outputId":"6390376a-3e13-4b33-8058-d22137bedf81"},"outputs":[{"output_type":"stream","name":"stdout","text":["JAX Backend: CPU\n","Primary Devices: 4\n"," - cpu (ID: 0)\n"," - cpu (ID: 1)\n"," - cpu (ID: 2)\n"," - cpu (ID: 3)\n","\n","Software Stack:\n"," - JAX: 0.7.2\n"," - Local Device Count: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n"]}],"source":["# @title Setup\n","import os\n","\n","# Must be set before JAX/XLA init to partition host CPU for pmap testing.\n","# Re-run after restarting the runtime if you need to change this.\n","os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=4'\n","\n","import jax\n","import jax.numpy as jnp\n","import numpy as np\n","import tensorflow as tf\n","\n","# Keep TF's hands off the GPU memory; JAX is the primary compute engine here.\n","tf.config.set_visible_devices([], 'GPU')\n","\n","def report_environment():\n","    backend = jax.default_backend()\n","    devices = jax.devices()\n","\n","    print(f\"JAX Backend: {backend.upper()}\")\n","    print(f\"Primary Devices: {len(devices)}\")\n","    for d in devices:\n","        print(f\" - {d.device_kind} (ID: {d.id})\")\n","\n","    if backend == 'gpu':\n","        print(\"\\nHardware Driver Status:\")\n","        # Direct check for driver/CUDA alignment\n","        try:\n","            !nvidia-smi --query-gpu=driver_version,compute_cap --format=csv,noheader\n","        except:\n","            print(\"nvidia-smi check failed.\")\n","\n","    print(f\"\\nSoftware Stack:\")\n","    print(f\" - JAX: {jax.__version__}\")\n","    print(f\" - Local Device Count: {jax.local_devices()}\")\n","\n","report_environment()"]},{"cell_type":"code","source":["# @title Data pipeline\n","import tensorflow_datasets as tfds\n","\n","def load_cifar10(batch_size, train=True):\n","    split = 'train' if train else 'test'\n","    ds, info = tfds.load('cifar10', split=split, with_info=True, as_supervised=True)\n","\n","    def preprocess(image, label):\n","        image = tf.cast(image, tf.float32) / 255.0\n","        label = tf.one_hot(label, 10)\n","        return image, label\n","\n","    ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","    if train:\n","        ds = ds.shuffle(10000).repeat()\n","\n","    ds = ds.batch(batch_size, drop_remainder=True)\n","    # Ensure the host stays ahead of the accelerator.\n","    ds = ds.prefetch(tf.data.AUTOTUNE)\n","\n","    # Use as_numpy to avoid TF tensor overhead in JAX.\n","    return tfds.as_numpy(ds), info\n","\n","# Initialize generators.\n","BATCH_SIZE = 64\n","train_ds_iterable, ds_info = load_cifar10(BATCH_SIZE, train=True)\n","test_ds_iterable, _ = load_cifar10(BATCH_SIZE, train=False)\n","\n","# Create iterators for manual stepping.\n","train_ds = iter(train_ds_iterable)\n","test_ds = iter(test_ds_iterable)\n","\n","# Verification.\n","sample_batch = next(train_ds)\n","print(f\"Batch shapes: Images {sample_batch[0].shape}, Labels {sample_batch[1].shape}\")\n","print(f\"Data types:  Images {sample_batch[0].dtype}, Labels {sample_batch[1].dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3SEor4v1wOD","executionInfo":{"status":"ok","timestamp":1768785768555,"user_tz":480,"elapsed":3238,"user":{"displayName":"Stefan Lafon","userId":"17149650627927548318"}},"outputId":"c4387ae3-0acc-4019-a08d-e0970bf9005d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch shapes: Images (64, 32, 32, 3), Labels (64, 10)\n","Data types:  Images float32, Labels float32\n"]}]}]}